# Identifying Duplicate Data

## 1. Record Counts

```sql
SELECT COUNT(*)
FROM health.user_logs
```

## 2. Unique Column Counts

```sql
SELECT COUNT(DISTINCT id)
FROM health.user_logs
```

## 3.Single Column Frequency Counts

- most frequent values within `measure` column using `GROUP BY`

```sql
SELECT 
	measure, COUNT(*) AS frequency,
	ROUND(100 * COUNT(*)/ SUM(COUNT(*)) OVER(), 2) AS percentage
	
FROM health.user_logs
GROUP BY measure
ORDER BY frequency DESC;
```

- Check the `id` column too

  ```sql
  SELECT 
  	id,
  	COUNT(*) AS frequency
  	ROUND(
    	100* COUNT(*) / SUM(COUNT(*)) OVER(),
    	2
    	) AS percentage
  FROM health.user_logs
  GROUP BY id
  ORDER BY frequency DESC
  LIMIT 10;
  ```

## 4. Individual Column Distributions

### 4.1 Measure Column

```sql
SELECT 
	measure_value,
	COUNT(*) AS frequency
FROM health.user_logs
GROUP BY 1
ORDER BY 2 DESC
LIMIT 10; 
	
```

### 4.2 Systolic

```sql	
SELECT
	systolic,
	COUNT(*) AS frequency
FROM health.user_logs
GROUP BY 1
ORDER BY 2 DESC
LIMIT 10; 
```

## 5. How to Deal with Duplicates

- A few ways to deal with duplicate records
  - Remove them in a `SELECT` statement
  - Recreating a 'clean' version of our dataset
  - Identify exactly which rows are duplicated for further investigation 
  - Simply ignore the duplicates and leave the dataset alone

### 5.1 Detecting Duplicate Records

```sql
SELECT COUNT(*)
FROM health.user_logs;
```

### 5.2 Remove All Duplicates

- apply `DISTINCT` keyword

  ```sql
  SELECT DISTINCT *
  FROM health.user_logs;
  ```

#### 5.2.1 Subqueries

- A subquery is essentially a query within a query

- Subquery must always have an alias

  ```sql
  SELECT COUNT(*)
  FROM(
  	SELECT DISTINCT *
  	FROM health.user_logs
  ) AS subqurey;
  ```

#### 5.2.2 Common Table Expression (CTE)

- CTE stands for `Common Table Expression`- and when we compare it to something simple like Excel, we can think of CTEs as transformations applied to raw data inside an existing Excel Sheet. 

- A CTE is a SQL query that manipulates existing data and stores the data outputs as new reference. 

- **CTE Example Query**

  ```sql
  WITH deduped_logs AS (
  	SELECT DISTINCT *
  	FROM health.user_logs)
  	
  SELECT COUNT(*)
  FROM deduped_logs;
  ```

#### 5.2.3 Temporary Tables

- we can also create a temporary table with only the unique values of our dataset after we run the `DISTINCT` query

- This is very common approach when you know that you will only be analyzing the ddeduplicated dataset, and you will ignore the original one with duplicates. 

- The main benefit of using temporary tables is removing the need to always run the same `DISTINCT` command everytime you want to run a query on the deduplicated records

- *first use following commond, super careful*

  `DROP TABLE IF EXISTS deduplicated_user_logs;`

- *create a new temporary table*

  ```sql
  CREATE TEMP TABLE deduplicated_user_logs AS
  SELECT DISTINCT *
  FROM health.user_logs;
  ```

- *query this newly created temporary table*

  ```sql
  SELECT *
  FROM deduplicated_user_logs
  LIMIT 10;
  ```

- *run that same `COUNT` on this deduplicated temp table*

  ```sql
  SELECT COUNT(*)
  FROM deduplicated_user_logs;
  ```

## 6. Identifying Duplicate Records

### 6.1. Group By Count On All Columns

- use a `GROUP BY` clause which ahs every single column in the grouping element and `COUNT` aggregate function. 

  ```sql
  SELECT
  	id, 
  	log_date,
  	measure,
  	measure_value,
  	systolic,
  	diastolic,
  	COUNT(*) AS frequency
  FROM health.user_logs
  GROUP BY id,
  				 log_date,
  				 measure,
  				 measure_value,
  				 systolic,
  				 diastolic
  ORDER BY frequency DESC;
  ```

### 6.2. Having Clause For Unique Duplicates

- Now the final step is to use the `HAVING` clause to further trim down our output by applying a condition on the same `COUNT` expression we were using for the `frequency` column we created in our previous query. 

- Since we only want the duplicated records to be returned, we would like that `COUNT(*)` value to be greater than 1. 

  ```SQL
  -- Don't forget to clean up any existing temp tables
  DROP TABLE IF EXISTS unique_duplicate_records;
  
  CREATE TEMPORARY TABLE unique_duplicate_records AS
  SELECT *
  FROM health.user_logs
  GROUP BY
  	id,
  	log_date,
  	measure,
  	measure_value,
  	systolic,
  	diastolic
  HAVING COUNT(*) > 1;
  
  -- Finally let's inspect the top 10 rows of our temp table 
  SELECT *
  FROM unique_duplicate_records
  LIMIT 10; 
  ```

### 6.3. Retaining Duplicate Counts (ETC method)

```sql
WITH groupby_counts AS(
	SELECT
		id,
		log_date,
		measure,
		measure_value,
		systolic,
		diastolic,
		COUNT(*) AS frequency
	FROM health.user_logs
	GROUP BY 
		id,
		log_date,
		measure,
		measure_value,
		systolic,
		diastolic
  )
 SELECT *
 FROM groupby_counts
 WHERE frequency > 1
 ORDER BY frequency DESC
 LIMIT 10; 
```

## 7. Ignoring Duplicate Values

- Sometimes perceive as duplicates might actually not be duplicated after all ( like above user_logs, maybe same user login into the website multiple times)

## Exericises

1. *Which `id` value has the most number of duplicate records in the `health.user_logs` table*

```sql
WITH groupby_counts AS (
  SELECT
    id,
    log_date,
    measure,
    measure_value,
    systolic,
    diastolic,
    COUNT(*) AS frequency
  FROM health.user_logs
  GROUP BY
    id,
    log_date,
    measure,
    measure_value,
    systolic,
    diastolic
)
SELECT
  id,
  SUM(frequency) AS total_duplicate_rows
FROM groupby_counts
WHERE frequency > 1
GROUP BY id
ORDER BY total_duplicate_rows DESC
LIMIT 10;
```

2. *Which `log_date` value had the most duplicate records after removing the max duplicate `id` value from question 1*

   ```sql
   WITH groupby_counts AS (
     SELECT
       id,
       log_date,
       measure,
       measure_value,
       systolic,
       diastolic,
       COUNT(*) AS frequency
     FROM health.user_logs
     WHERE id != '054250c692e07a9fa9e62e345231df4b54ff435d'
     GROUP BY
       id,
       log_date,
       measure,
       measure_value,
       systolic,
       diastolic
   )
   SELECT log_date,
   			 sum(frequency) AS total_duplicate_rows
   FROM groupby_counts
   WHERE frequency > 1
   GROUP BY log_date
   ORDER BY total_duplicate_rows DESC
   LIMIT 10;
   ```

3. *Which `measure_value` had the most ocurences in the `health.user_logs` value when measure = 'weight'?*

   ```sql
   SELECT measure_value, COUNT(*) AS frequency
   FROM health.log_user
   WHERE measure = 'weight'
   GROUP BY measure_value
   ORDER BY frequency DESC
   LIMIT 10; 
   ```

4. *How many single duplicated rows exist when `measure='blood_pressure` in the `health.user_logs`? How about the total number of duplicated records in the same table?*

   ```sql
   WITH groupby_counts AS (
   	SELECT
   		id, 
   		log_date,
   		measure,
   		measure_value,
   		systolic,
   		diastolic,
   		COUNT(*) AS frequency	
   	FROM health.user_logs
   	WHERE measure = 'blood_pressure'
   	GROUP BY 
   		id,
   		log_date,
   		measure,
   		measure_value,
   		systolic,
   		diastolic
   )
   SELECT 
   	COUNT(*) AS single_duplicate_rows
   	SUM(frequency) AS total_duplicate_records
   FROM groupby_counts
   WHERE frequency > 1;
   ```

5. **Percentage of table Records**

   1. *What percentage of records `measure_value = 0` when `measure = 'blood_pressure'` in the `health.user_logs` table? How many records are there also for this same condition?*

      ```sql
      WITH all_measure_values AS (
        SELECT
          measure_value,
          COUNT(*) AS total_records,
          SUM(COUNT(*)) OVER() AS overall_total
        FROM health.user_logs
        WHERE measure = 'blood_pressure'
        GROUP BY 1)
        
      SELECT 
      	measure_value, 
      	total_records, 
      	overall_total, 
      	ROUND(100 * total_records::NUMERIC / overall_total, 2) AS percentage
      FROM all_measure_values
      WHERE measure_value = 0;
      
      ```

6. *What percentage of records are duplicates in the `health.user_logs` table?*

   ```sql
   WITH groupby_counts AS (
     SELECT
       id,
       log_date,
       measure,
       measure_value,
       systolic,
       diastolic,
       COUNT(*) AS frequency
     FROM health.user_logs
     GROUP BY
       id,
       log_date,
       measure,
       measure_value,
       systolic,
       diastolic
     )
   SELECT 
     -- Need to subtract 1 from the frequency to count actual duplicates
     -- Also don't forget about the integer floor division
     ROUND(
       100 * SUM(CASE
               WHEN frequency > 1 THEN frequency - 1
               ELSE 0 END)::NUMERIC / SUM(frequency),2) AS duplicate_percentage
   FROM groupby_counts;
   ```

## Conclusion

- Remove all duplicated records from a dataset using `DISTINCT`
- Use Common Table Expressions and subqueries to calculate unique record counts
- Clean up existing temporary tables using the `DROP TABLE IF EXIST`
- Create temporary tables using the results from a `SELECT` statement
- Detect the presence of duplicates by comparing basic record counts with unique counts
- Identify exact duplicate records using a `GROUP BY` on all columns in a table
- Calculate the number of occurences a records appears in a table
- Filter records from a `SELECT` statement with a `GROUP BY` using the `HAVING ` clasuse

